---
title: "Assignment_202320860"
author: "202320860"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
    toc_depth: 4
---
```{r global_options, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```

My public Github repository for the final assignment's code can be found [here](https://github.com/BBBecky0913/MY472_Assignment2.git)

# 1 Introduction
A brief introduction to the research question and your approach to answering it. You do not need to cite any literature or write a literature review.
å¯¹ç ”ç©¶é—®é¢˜çš„ç®€è¦ä»‹ç»ä»¥åŠå›ç­”è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•ã€‚ä½ ä¸éœ€è¦å¼•ç”¨ä»»ä½•æ–‡çŒ®æˆ–å†™ä¸€ç¯‡æ–‡çŒ®è¯„è®ºã€‚
## 1.1 Research Question

## 1.2 Research Area
ç ”ç©¶åŒºåŸŸå’Œæ—¶é—´
ä»‹ç»å‡ ç§ç ”ç©¶å°ºåº¦(åœ¨ä¼¦æ•¦å†…éƒ¨çš„)

idå’Œname
*é¦–å…ˆå¿…é¡»å¾—çŸ¥é“çš„æ˜¯PFAs**
London_PFAs <- c("metropolitan", "city-of-london")

åŠ è½½æ•°æ®ï¼Œå¹¶æ’ç»˜å›¾
```{r}

```


## 1.3 Research Methods
```{r include=FALSE}
if(!require("tidyverse")) install.packages("tidyverse") 
if(!require("magrittr")) install.packages("magrittr") 
if(!require("lubridate")) install.packages("lubridate") 
if(!require("dplyr")) install.packages("dplyr") 
if(!require("stringr")) install.packages("stringr") 
if(!require("quanteda")) install.packages("quanteda") 
if(!require("tidyverse")) install.packages("tidyverse") 
if(!require("sf")) install.packages("sf") 
if(!require("RSQLite")) install.packages("RSQLite") 
if(!require("RSelenium")) install.packages("RSelenium") 
if(!require("netstat")) install.packages("netstat") 
if(!require("quanteda.textplots")) install.packages("quanteda.textplots") 
if(!require("httr")) install.packages("httr") 
if(!require("jsonlite")) install.packages("jsonlite") 
if(!require("quanteda.textstats")) install.packages("quanteda.textstats") 
if(!require("ggplot2")) install.packages("ggplot2") 
if(!require("ggrepel")) install.packages("ggrepel") 
if(!require("cowplot")) install.packages("cowplot")
if(!require("ggrepel")) install.packages("ggrepel") 
if(!require("RColorBrewer")) install.packages("RColorBrewer") 
if(!require("viridis")) install.packages("viridis") 
if(!require("wesanderson")) install.packages("wesanderson") 
if(!require("ggmap")) install.packages("ggmap") 
if(!require("ggspatial")) install.packages("ggspatial") 
if(!require("biscale")) install.packages("biscale") 
```

å…¨å±€ä½¿ç”¨åŒ…
```{r results='hide'} 
# data operations
library(magrittr)
library(tidyverse)
library(dplyr, warn.conflicts = FALSE)
options(dplyr.summarise.inform = FALSE)

# texual analysis
library(stringr)
library(glue)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)

# data format transformation
library(lubridate)

# database inquiry
library(DBI)
library(RSQLite)

# web scraping
library(httr)
library(rvest)
library(RSelenium)
library(jsonlite)

# spatial analysis
library(sf)

# data visualization
library(ggplot2)
library(cowplot)
library(RColorBrewer)
library(viridis)
library(ggrepel)
library(ggmap)
library(ggspatial)

# local packages
# library(biscale)
```


## 1.4 ğŸ˜‚ Research Design
åŒ…æ‹¬å›¾è§£
1 é‚£å‡ ç§ç©ºé—´ç»Ÿè®¡å’Œé“¾æ¥å…³ç³»
LSOAï¼ˆä¼¦æ•¦å¾ˆå¤šï¼‰ã€Neighborhoodï¼ˆä»…åšpriority)
2 æ€ä¹ˆèåˆ

# 2 Data Description
A discussion of the data sources you used how you accessed them how you processed the data, the structure of your final analysis datasets) and so on.
è®¨è®ºæ‚¨ä½¿ç”¨çš„æ•°æ®æºã€å¦‚ä½•è®¿é—®å®ƒä»¬ã€å¦‚ä½•å¤„ç†æ•°æ®ã€æœ€ç»ˆåˆ†ææ•°æ®é›†çš„ç»“æ„ï¼Œç­‰ç­‰ã€‚

## 2.1 Data Source
æºå€ï¼Œè®¿é—®ï¼ˆç›´æ¥ä¸‹è½½ï¼Œçˆ¬å–ï¼ŒAPIï¼‰
## 2.2 Data Processing
ä»£ç©ºé—´ä½ç½®ä¿¡æ¯æ•°æ®çš„ç©ºé—´åŒ–
è¡¨æ ¼æ•°æ®çš„è½¬æ¢
æ–‡æœ¬æ•°æ®çš„æ¸…ç†ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰
## 2.3 Data Structure
æ–‡æœ¬æ•°æ®ï¼Œè¡¨æ•°æ®ï¼Œç©ºé—´æ•°æ®
æ•°æ®åº“å­˜å‚¨

# 3 Analysis
A presentation of your analysis including figures/graphs/maps and a discussion of your findings. In general, we do not expect you to conduct or interpret any formal statistical tests though you may do this if you wish. memember that your discussion should translate your specific analysis and results back to the level of the research question.
ä»‹ç»ä½ çš„åˆ†æï¼ŒåŒ…æ‹¬æ•°å­—/å›¾è¡¨/åœ°å›¾ï¼Œå¹¶è®¨è®ºä½ çš„å‘ç°ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬ä¸æœŸæœ›ä½ è¿›è¡Œæˆ–è§£é‡Šä»» ä½•æ­£å¼çš„ç»Ÿè®¡æµ‹è¯•ï¼Œä½†å¦‚æœä½ æ„¿æ„ï¼Œä½ å¯ä»¥è¿™æ ·åšã€‚è®°ä½ï¼Œä½ ä»¬çš„è®¨è®ºåº”è¯¥å°†ä½ ä»¬çš„å…·ä½“åˆ†æå’Œç»“æœç¿»è¯‘å›ç ”ç©¶é—®é¢˜çš„å±‚æ¬¡ã€‚

```{r}
path_to_folder <- getwd()
```

## 3.1 ğŸ’ª Identity Prejudice

### ğŸŒ¹3.1.1 Basic Work

#### 1) Stop-and-Search Data Collection 

##### â‘  Gathering S&S Data from API
éœ€è¦è§£é‡Šforce id = PFA  force name = force
```{r}
London_PFAs <- c("metropolitan", "city-of-london")

# get the forces list in London. We can find that each Police Force Area(force_id in api json) corresponds to one police force(force_name)
force_list <- httr::content(GET("https://data.police.uk/api/forces"), "parsed") %>% lapply(unlist)

London_force_PFA <- data.frame()
London_forces <- c()

for (force in force_list){
  if (force["id"] %in% London_PFAs){
    force <- as.data.frame(t(force))
    London_force_PFA <- rbind(London_force_PFA, force)
  }
}

# å°†force_nameæ”¹å†™æˆapiè§„å®šçš„urlå†…éƒ¨å‚æ•°å½¢å¼
# London_forces <- London_force_PFA$name <- do.call(c, lapply(London_force_PFA$name, function(x) gsub(" ", "-", x)))

London_force_PFA
# London_forces
```

ä»‹ç»tibbleè¡¨æ ¼é‡Œçš„å˜é‡å«ä¹‰
```{r eval=FALSE}
London_SS_tibble <- tibble()
year_dates <- "2023-11"

for (PFA in London_PFAs){
  for (year_date in year_dates){
    # get neighborhoods' urls during research period
    SS_url <- sprintf("https://data.police.uk/api/stops-force?force=%s&date=%s", PFA, year_date)
    SS_json <- SS_url %>% GET() %>%  httr::content("parsed")     # parse the content returned from our GET request
    for (SS in SS_json){
      SS <- SS %>% unlist() %>% t() %>% as_tibble()
      SS$datetime  <-  ymd_hms(SS$datetime)
      SS$PFA_name <- PFA
      SS$force <- London_force_PFA[London_force_PFA$id == PFA, "name"]
      London_SS_tibble <- bind_rows(London_SS_tibble, SS)  # bind_rows can combine two dfs with cols not exactly same
    }
  }
}
```

##### â‘¡ S&S Data Preprocessing
å¯¹ç”Ÿæˆçš„åŸå§‹tibbleè¿›è¡Œäº†å»é™¤ç©ºå€¼ï¼ˆ9303->6906)ã€é‡å‘½åå’Œåˆ—é‡æ–°æ’åºåå¾—åˆ°æœ€ç»ˆè¡¨æ ¼
some adjustments for the tibble
```{r eval=FALSE, include=FALSE}
# delete those rows which have at least a NA value in these columns written below
London_SS_tibble <- London_SS_tibble %>% 
                    filter(!is.na(longitude),
                           !is.na(latitude),
                           !is.na(gender),
                           !is.na(age_range),
                           !is.na(self_defined_ethnicity),
                           !is.na(officer_defined_ethnicity),
                           !is.na(object_of_search),
                           !is.na(outcome))

# rename some cols
London_SS_tibble <- London_SS_tibble %>%
  rename(
    street_id = location.street.id,
    street_name = location.street.name,
    longitude = location.longitude,
    latitude = location.latitude,
    outcome_object_id = outcome_object.id,
    outcome_object_name = outcome_object.name,
  )

# select and adjust the col sequence of tibble
London_SS_tibble <- London_SS_tibble %>% select(datetime, gender, age_range,
                                                self_defined_ethnicity,
                                                officer_defined_ethnicity, 
                                                longitude, latitude, 
                                                object_of_search, outcome,
                                                outcome_linked_to_object_of_search,
                                                removal_of_more_than_outer_clothing,
                                                street_id, street_name, force, PFA_name,
                                                type, involved_person,                                                                       legislation)
London_SS_tibble
```

```{r echo=FALSE, paged.print=TRUE}
# saveRDS(London_SS_tibble, "RDS_data/London_SS_tibble.rds")
London_SS_tibble<- readRDS( "RDS_data/London_SS_tibble.rds")
London_SS_tibble
```

#### 2) Chart Plot Template

##### â‘  Bar Chart
```{r eval=FALSE}
bar_plot <- function(data, x="", y, fill, 
                     is_facet = FALSE, 
                     viridis, is_discrete = TRUE,
                     title, title_size, ylab,
                     geom_text_size,
                     legend_lab, legend_item = c(),legend_title_size,
                     axis_title_size,
                     axis_text_size){
  
  plot <- plot <- ggplot(data, aes(x = x, y = y, fill = fill)) +
          geom_bar(stat = "identity") +
          labs(fill = legend_lab) +  
          scale_fill_viridis(option = viridis, direction = -1, discrete = is_discrete, begin = 0.4, end = 1) +
          xlab("") +
          ylab(ylab) + 
          ggtitle(title)+
          geom_text_repel(aes(label=y), vjust=1.6,
                          color="grey2", size=geom_text_size, alpha = 0.8) +
          theme(
            plot.title = element_text(size = title_size, face ='bold', hjust =0.08, vjust = 1),
            panel.background = element_blank(),
            panel.border = element_rect(colour = "black", fill = NA, linewidth = 0.5),
            strip.background = element_blank(),
            strip.text = element_text(size = 15, face ='bold'),
            legend.title = element_text(size = legend_title_size, face ='bold'),
            legend.text = element_text(size = 13),
            legend.key.size = unit(1, "cm"),
            legend.spacing.y = unit(0.3, "cm"),
            axis.title.x = element_text(size = axis_title_size[1]), 
            axis.title.y = element_text(size = axis_title_size[2]),  
            axis.text.x = element_text(size = axis_text_size[1]),   
            axis.text.y = element_text(size = axis_text_size[2]))
  
  if (is_facet == TRUE){
    # facet_wrap
    plot <- plot + facet_wrap(~ Var2, labeller = as_labeller(legend_item))
  }
  
  return(plot)
}
```
##### â‘¡ Pie Chart

```{r eval=FALSE}
pie_plot <- function(data, viridis, legend_lab, legend_loc){
  
  # first calculate the new variables (e.g. proportion) for plotting
  data <- data %>% 
    mutate(prop = Freq / sum(Freq) *100,
           prop_text = paste0(round(prop, 2), "%"),
           ypos = cumsum(prop)- 0.5*prop)
  
  # then plot
  plot <- ggplot(data, aes(x = "", y = Freq, fill = Var1)) +
          coord_polar("y") +
          # scale_fill_manual(values = palette) +
          scale_fill_viridis(option = viridis, direction = -1, discrete = TRUE, begin = 0.4, end = 1) +
          labs(fill = legend_lab) +  
          geom_col(color = "white") +
          geom_label_repel(aes(label = prop_text),
                     color = "black",
                     size = 7,
                     label.size = 0.9,
                     label.r = unit(0.3, "lines"),
                     label.padding = unit(0.8, "lines"),  # Amount of padding around label
                     position = position_stack(vjust = 0.5),
                     show.legend = FALSE) +
          theme_void() +
          theme(plot.margin = margin(t = 1.5, r = -10, 
                                     b = -0.8, l = -13.5, "cm"),
                legend.title = element_text(size = 20, face ='bold'),
                legend.text = element_text(size = 18),
                legend.key.size = unit(1, "cm"),
                legend.spacing.y = unit(0.3, "cm"), 
                legend.position = legend_loc)
  return(plot)
}

```
### ğŸŒ¹3.1.2 Descriptive Statistics

#### 1) ğŸ¤¢ Identity Structure
Identity: 
gender, age_range, (detailed) self_defined_ethnicity, (simplified) officer_defined_ethnicity

Crime type:
object_of_searchï¼ˆ9ï¼‰, legislationï¼ˆ4ï¼‰

Crime severity (including mistake): 
outcomeï¼ˆ7ï¼‰, $removal_of_more_than_outer_clothingï¼ˆ2ï¼‰

Misjudgment: (when the outcome is not linked to object or no crime)
outcome =  A no further action disposal,
outcome_linked_to_object_of_search

##### â‘  Extract the misjudged S&S
è¯¯åˆ¤: å»é™¤S&Såˆ¤æ–­æ­£ç¡®çš„æ•°æ®ï¼Œæ’é™¤æŸç±»ç‰¹å¾äººç¾¤çš„é«˜è¿æ³•ç‡ï¼Œèƒ½å¤Ÿæ›´åŠ çœŸå®çš„çœ‹å‡ºpoliceå¯¹æŸä¸€ç±»äººç¾¤çš„åè§  è¯´æ˜è¿™ä¸ªäººä¸æ˜¯çœŸçš„è¿æ³•åªæ˜¯é­åˆ°äº†å«Œç–‘
"misjudged Stop and Search" è¿™ä¸ªçŸ­è¯­å¯èƒ½æœ‰å‡ ç§å«ä¹‰ï¼Œå–å†³äºä¸Šä¸‹æ–‡ã€‚åœ¨ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œå®ƒå¯èƒ½æŒ‡çš„æ˜¯ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š

é”™è¯¯çš„åˆ¤æ–­ï¼šè¿™å¯èƒ½æ„å‘³ç€è­¦å¯Ÿåœ¨æ‰§è¡Œ "Stop and Search"ï¼ˆå³åœæ­¢å¹¶æœæŸ¥ï¼‰æ“ä½œæ—¶ï¼ŒåŸºäºé”™è¯¯æˆ–ä¸å……åˆ†çš„ä¿¡æ¯æˆ–ä¾æ®åšå‡ºäº†å†³å®šã€‚ä¾‹å¦‚ï¼Œå¯èƒ½æ˜¯åŸºäºé”™è¯¯çš„å«Œç–‘æˆ–è¯¯è§£çš„æƒ…æŠ¥è€Œå¯¹æŸäººè¿›è¡Œäº†æœæŸ¥ã€‚

ç§æ—æˆ–ç¤¾ä¼šåè§ï¼šè¿™ä¸ªçŸ­è¯­ä¹Ÿå¯èƒ½æŒ‡ "Stop and Search" æ“ä½œä¸­ä½“ç°çš„ç§æ—æˆ–ç¤¾ä¼šåè§ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæŸä¸ªç‰¹å®šç§æ—æˆ–ç¤¾ä¼šç¾¤ä½“åœ¨æ²¡æœ‰å……åˆ†ç†ç”±çš„æƒ…å†µä¸‹è¢«è¿‡åº¦æœæŸ¥ï¼Œè¿™å¯èƒ½è¢«è®¤ä¸ºæ˜¯ä¸€ç§è¯¯åˆ¤ã€‚

ä¸æ°å½“æˆ–éæ³•çš„æœæŸ¥ï¼šåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œ"misjudged Stop and Search" å¯èƒ½æ„å‘³ç€æœæŸ¥æœ¬èº«æ˜¯ä¸æ°å½“çš„æˆ–è¿åäº†æ³•å¾‹è§„å®šã€‚è¿™å¯èƒ½åŒ…æ‹¬æœªç»æˆæƒçš„æœæŸ¥ã€è¶…å‡ºæ³•å¾‹è®¸å¯èŒƒå›´çš„æœæŸ¥ï¼Œæˆ–è€…æ˜¯åœ¨æ²¡æœ‰åˆç†æ€€ç–‘çš„æƒ…å†µä¸‹è¿›è¡Œçš„æœæŸ¥ã€‚

```{r paged.print=TRUE}
# é€‰å–æƒ³è¦åˆ†ç±»ç»Ÿè®¡çš„åˆ—
SS_col_names <- c("gender", "age_range", "self_defined_ethnicity", "officer_defined_ethnicity", "object_of_search", "outcome", "outcome_linked_to_object_of_search", "removal_of_more_than_outer_clothing", "legislation")

SS_misjudgment <- London_SS_tibble %>% filter(outcome == "A no further action disposal")

# è¿­ä»£æ¯ä¸€åˆ—ï¼Œè®¡ç®—å”¯ä¸€å€¼åŠå…¶å‡ºç°æ¬¡æ•°,å°†æ¯ä¸ªå˜é‡listè½¬åŒ–ä¸ºdataframeï¼Œä»¥ä¾¿åˆ¶å›¾
SS_col_counts <- SS_misjudgment[SS_col_names] %>% lapply(table) %>% lapply(data.frame)
SS_col_counts
```
##### â‘¡ Indentity Structure Statistics
- Gender, Age_range and Ethnicity (defined by self and officer)
```{r eval=FALSE, fig.width=22, fig.height=6}
gender_plot <- pie_plot(data = SS_col_counts$gender, 
                        legend_lab = "Gender",
                        viridis = "mako", 
                        legend_loc = c(1.02, 0.25))

age_range_plot <- pie_plot(data = SS_col_counts$age_range, 
                           viridis = "mako", 
                           legend_lab = "Age Range",
                           legend_loc = c(1.06, 0.28))

ethnicity_plot <- pie_plot(data = SS_col_counts$officer_defined_ethnicity,
                           viridis = "mako", 
                           legend_lab = "Ethnicity",
                           legend_loc = c(1.02, 0.25))

identity_plot <- plot_grid(gender_plot, age_range_plot, ethnicity_plot, nrow = 1)

final_identity_plot <- ggdraw() + 
              draw_plot(identity_plot) +
              draw_label('Pie Charts for Proportions of People with Different Identities under Stop-and-search', 
                         fontface = 'bold', size = 32, x = 0.5, 
                         vjust = -7.5, hjust = 0.5)
final_identity_plot
```

```{r echo=FALSE, fig.width=22, fig.height=6}
# saveRDS(final_identity_plot, "RDS_data/final_identity_plot.rds")
final_identity_plot<- readRDS( "RDS_data/final_identity_plot.rds")
final_identity_plot
```

- Data preprocessing
```{r}
ethnicity_detail <- SS_col_counts$self_defined_ethnicity

# å°†self_defined_ethnicityä¸­çš„å¤§ç±»å’Œç»†åˆ†ç±»åˆ†å¼€æˆä¸¤åˆ—ï¼Œä¾¿äºåç»­çš„facetåˆ¶å›¾
ethnicity_detail$Var2 <- unlist(lapply(ethnicity_detail$Var1, function(x) gsub("(^[^-]*)-[^-]*", "\\1", x))) %>% trimws()  # å»é™¤é¦–æœ«å°¾çš„ç©ºæ ¼

# Subclass
ethnicity_detail$Var1 <- unlist(lapply(ethnicity_detail$Var1, function(x) gsub("^[^-]*-", "", x))) %>% trimws()
```

- Plot Stacked Bar Chart for Proportions of Self-defined Ethnicity under Stop-and-search
```{r echo=FALSE, fig.width=11, fig.height=7.5}
# first calculate the new variables (e.g. proportion) for plotting
ethnicity_detail <- ethnicity_detail %>% 
mutate(prop = round(Freq / sum(Freq) *100, 1)) %>% 
# update factor levels of subclass according to the proportion in a descending order for following visualization (default is sorting by first letter)
arrange(desc(prop)) %>%
mutate(Var1 = factor(Var1, levels = Var1))
```

```{r eval=FALSE, fig.width=11, fig.height=7.5}
# ç®€åŒ–åˆ†ç±»å
Ethnic_Class <- c("White" = "White related",
                  "Asian/Asian British" = "Asian related",
                  "Black/African/Caribbean/Black British" = "Black related",
                  "Mixed/Multiple ethnic groups" = "Mixed/ Multiple",
                  "Other ethnic group" = "Other group")

# choose stacked bar 
ethnicity_detail_plot <- bar_plot(data = ethnicity_detail,
                                  y = ethnicity_detail$prop, fill = ethnicity_detail$Var1,
                                  is_facet = TRUE,
                                  viridis = "mako",
                                  title = "Stacked Bar Chart for Proportions of Self-defined Ethnicity under Stop-and-search", 
                                  ylab = "Proportion (%)",
                                  title_size=19,
                                  geom_text_size = 5,
                                  legend_title_size = 14,
                                  axis_title_size = c(16,16),
                                  axis_text_size = c(12,12),
                                  legend_lab = "Self-defined Ethnicity",
                                  legend_item = Ethnic_Class)

ethnicity_detail_plot
```

```{r echo=FALSE, fig.width=11, fig.height=7.5}
# saveRDS(ethnicity_detail_plot, "RDS_data/ethnicity_detail_plot.rds")
ethnicity_detail_plot<- readRDS( "RDS_data/ethnicity_detail_plot.rds")
ethnicity_detail_plot
```

#### 2) ğŸ¤¢ Identity Bias

##### â‘  Import 2021 Uk Census Data 
```{r}
# current path
path_to_folder_losa <- paste0(getwd(), "/All_data/0_LSOA_all_data/")

Age_range_census <- read_csv(paste0(path_to_folder_losa,"Age_5Bands.csv"))
Ethnic_group_census <- read.csv(paste0(path_to_folder_losa,'Ethnic_Group.csv'))
Sex_census <- read.csv(paste0(path_to_folder_losa,'Sex.csv'))
```

##### â‘¡ Zoom into London LSOAs
ä»ONSç½‘ç«™ä¸Šè·å–äº†LSOA_2021_EW_BGCï¼Œå¹¶ä¸ä¼¦æ•¦è¾¹ç•Œè£å‰ªå¾—åˆ°Londonçš„LSOAç©ºé—´æ•°æ®
```{r}
# download the LSOA boundary data collected before
London_lsoa_sf <- read_sf(paste0(path_to_folder_losa,"London_LSOA.shp"))

Age_range_London_lsoa <- left_join(London_lsoa_sf, Age_range_census, by = c("LSOA21CD"= "geography code"))

Ethnic_group_London_lsoa <- left_join(London_lsoa_sf, Ethnic_group_census, by = c("LSOA21CD"= "geography.code"))

Sex_London_lsoa <- left_join(London_lsoa_sf, Sex_census, by = c("LSOA21CD"= "geography.code"))
```

##### â‘¢ Summarise by S&S classification
```{r}
# summarise by age bands
Age_range_London_lsoa$Age_range_under_10  <- as_tibble(Age_range_London_lsoa) %>% 
  select("Age: Aged 4 years and under", "Age: Aged 5 to 9 years") %>% rowSums()

Age_range_London_lsoa$Age_range_10_19 <- as_tibble(Age_range_London_lsoa) %>% 
  select("Age: Aged 10 to 14 years", "Age: Aged 15 to 19 years") %>% rowSums()

Age_range_London_lsoa$Age_range_20_24 <- as_tibble(Age_range_London_lsoa) %>% 
  select("Age: Aged 20 to 24 years") %>% rowSums()

Age_range_London_lsoa$Age_range_25_34 <- as_tibble(Age_range_London_lsoa) %>% 
  select("Age: Aged 25 to 29 years", "Age: Aged 30 to 34 years") %>% rowSums()

Age_range_London_lsoa$Age_range_over_34 <- as_tibble(Age_range_London_lsoa) %>% 
  select("Age: Aged 35 to 39 years", "Age: Aged 40 to 44 years",
         "Age: Aged 45 to 49 years", "Age: Aged 50 to 54 years",
         "Age: Aged 55 to 59 years", "Age: Aged 60 to 64 years",
         "Age: Aged 65 to 69 years", "Age: Aged 70 to 74 years",
         "Age: Aged 75 to 79 years", "Age: Aged 80 to 84 years",
         "Age: Aged 85 years and over") %>% rowSums()
# calculate the overall mean proportions of age range
Age_range_prop_all <- Age_range_London_lsoa %>% summarise(pop_all = sum(`Age: Total`),
                                                `under 10` = mean(Age_range_under_10/ `Age: Total`),
                                                `10-17` = mean(Age_range_10_19/ `Age: Total`),
                                                `18-24` = mean(Age_range_20_24/ `Age: Total`),
                                                `25-34` = mean(Age_range_25_34/ `Age: Total`),
                                                `over 34` = mean(Age_range_over_34/ `Age: Total`)) %>% 
                                    as_tibble() %>% select(-geometry) %>% 
                                    pivot_longer(cols = c("under 10","10-17","18-24","25-34","over 34"), 
                                                 names_to = "Var1", 
                                                 values_to = "prop")

# calculate the proportions of Ethnic_group
Ethnic_London_lsoa <- Ethnic_group_London_lsoa %>% mutate(
                     Asian_prop = Ethnic.group..Asian..Asian.British.or.Asian.Welsh / Ethnic.group..Total..All.usual.residents,
                     Black_prop = Ethnic.group..Black..Black.British..Black.Welsh..Caribbean.or.African / Ethnic.group..Total..All.usual.residents,
                     White_prop = Ethnic.group..White / Ethnic.group..Total..All.usual.residents,
                     Mixed_prop = Ethnic.group..Mixed.or.Multiple.ethnic.groups / Ethnic.group..Total..All.usual.residents,
                     Other_prop = Ethnic.group..Other.ethnic.group / Ethnic.group..Total..All.usual.residents)
# summarise the overall mean proportion of Ethnic_group
Ethnic_prop_all <- Ethnic_group_London_lsoa %>% summarise(pop_all = sum(Ethnic.group..Total..All.usual.residents),
                                                Asian = mean(Asian_prop),
                                                Black = mean(Black_prop),
                                                White = mean(White_prop),
                                                Mixed = mean(Mixed_prop),
                                                Other = mean(Other_prop)) %>% 
                                    as_tibble() %>% select(-geometry) %>% 
                                    pivot_longer(cols = c("Asian","Black","White","Mixed", "Other"), 
                                                 names_to = "Var1", 
                                                 values_to = "prop")

# calculate the proportions of sex
Sex_London_lsoa <- Sex_London_lsoa %>% mutate(Male_prop = Sex..Male..measures..Value/ Sex..All.persons..measures..Value,
                                              Female_prop = Sex..Female..measures..Value/ Sex..All.persons..measures..Value)
# summarise the overall mean proportion of sex
Sex_prop_all <- Sex_London_lsoa %>% summarise(pop_all = sum(Sex..All.persons..measures..Value),
                                                Male = mean(Male_prop),
                                                Female = mean(Female_prop)) %>% 
                                    as_tibble() %>% select(-geometry) %>% 
                                    pivot_longer(cols = c("Male","Female"), 
                                                 names_to = "Var1", 
                                                 values_to = "prop")
```

```{r echo=FALSE}
# saveRDS(Age_range_London_lsoa, "RDS_data/Age_range_London_lsoa.rds")
Age_range_London_lsoa <- readRDS( "RDS_data/Age_range_London_lsoa.rds")
# saveRDS(Age_range_prop_all, "RDS_data/Age_range_prop_all.rds")
Age_range_prop_all <- readRDS( "RDS_data/Age_range_prop_all.rds")

# saveRDS(Ethnic_London_lsoa, "RDS_data/Ethnic_group_London_lsoa.rds")
Ethnic_London_lsoa <- readRDS( "RDS_data/Ethnic_group_London_lsoa.rds")
# saveRDS(Ethnic_prop_all, "RDS_data/Ethnic_prop_all.rds")
Ethnic_prop_all <- readRDS( "RDS_data/Ethnic_prop_all.rds")

# saveRDS(Sex_London_lsoa, "RDS_data/Sex_London_lsoa.rds")
Sex_London_lsoa <- readRDS( "RDS_data/Sex_London_lsoa.rds")
# saveRDS(Sex_prop_all, "RDS_data/Sex_prop_all.rds")
Sex_prop_all <- readRDS( "RDS_data/Sex_prop_all.rds")
```

##### â‘£ Disproportionality in S&S

- è®¡ç®—èº«ä»½ç‰¹å¾åœ¨ "Stop and Search" ä¸­çš„æ¯”ä¾‹ä¸åœ¨æ€»äººå£ä¸­çš„æ¯”ä¾‹ä¹‹é—´çš„å·®å¼‚
```{r paged.print=TRUE}
Sex_prop_SS <- SS_col_counts$gender %>% 
    mutate(prop = Freq / sum(Freq), Var1 = as.character(Var1)) 

Age_range_prop_SS <- SS_col_counts$age_range %>% 
    mutate(prop = Freq / sum(Freq), Var1 = as.character(Var1))
Age_range_prop_SS

Ethnic_prop_SS <- ethnicity_detail %>% group_by(Var2) %>% summarise(Freq = sum(Freq)) %>% 
                   mutate(prop = Freq / sum(Freq),
                          Var1 = c("Asian", "Black", "Mixed", "Other", "White"))

Sex_disprop <- Sex_prop_SS %>% inner_join(Sex_prop_all, by = c("Var1" = "Var1")) %>% 
                               mutate(Sex_disprop = round(prop.x/prop.y - 1,2)) %>% select(Var1, Sex_disprop) %>% 
                               arrange(desc(Sex_disprop))
Sex_disprop

Age_range_disprop <- Age_range_prop_SS %>% inner_join(Age_range_prop_all, by = c("Var1" = "Var1")) %>% 
                               mutate(Age_range_disprop = round(prop.x/prop.y - 1,2)) %>% select(Var1, Age_range_disprop) %>% 
                               arrange(desc(Age_range_prop_SS))
Age_range_disprop

Ethnic_disprop <- Ethnic_prop_SS %>% inner_join(Ethnic_prop_all, by = c("Var1" = "Var1")) %>% 
                               mutate(Ethnic_disprop = round(prop.x/prop.y - 1,2)) %>% select(Var1, Ethnic_disprop) %>% 
                               arrange(desc(Ethnic_disprop))
Ethnic_disprop
```

```{r eval=FALSE, fig.width=20, fig.height=8}

Sex_disprop_bar <- bar_plot(data = Sex_disprop, x = Sex_disprop$Var1, 
                            y = Sex_disprop$Sex_disprop, fill = Sex_disprop$Sex_disprop,
                            viridis = "mako", is_discrete = FALSE,
                            title = " ", title_size = 50, ylab = "Disproportionality",
                            legend_lab = "Sex",
                            legend_title_size = 25,
                            geom_text_size = 6,
                            axis_title_size = c(18,18),
                            axis_text_size = c(22,22))

Age_range_disprop_bar <- bar_plot(data = Age_range_disprop, x = Age_range_disprop$Var1, 
                            y = Age_range_disprop$Age_range_disprop, fill = Age_range_disprop$Age_range_disprop,
                            viridis = "mako", is_discrete = FALSE,
                            title = " ", title_size = 50, ylab = "Disproportionality",
                            legend_lab = "Age",
                            legend_title_size = 25,
                            geom_text_size = 6,
                            axis_title_size = c(18,18),
                            axis_text_size = c(20,20))

Ethnic_disprop_bar <- bar_plot(data = Ethnic_disprop, x = Ethnic_disprop$Var1, 
                            y = Ethnic_disprop$Ethnic_disprop, fill = Ethnic_disprop$Ethnic_disprop,
                            viridis = "mako", is_discrete = FALSE,
                            title = " ", title_size = 50, ylab = "Disproportionality",
                            legend_lab = "Ethnicity",
                            legend_title_size = 25,
                            geom_text_size = 6,
                            axis_title_size = c(18,18),
                            axis_text_size = c(22,22))

disprop_plot <- plot_grid(Sex_disprop_bar, Age_range_disprop_bar, Ethnic_disprop_bar, nrow = 1)

final_disprop_plot <- ggdraw() + 
              draw_plot(disprop_plot) +
              draw_label('Different Identity Features Disproportionality in Stop-and-Search', 
                         fontface = 'bold', size = 28, x = 0.5, 
                         vjust = -12, hjust = 0.5)
final_disprop_plot
```

### ğŸŒ¹3.1.3 ğŸ¤¢ Correlation Analysis
éœ€è¦ï¼šä¹ä¸‡ä¸ªä¸èƒ½åšï¼Œåªèƒ½LSOAï¼Œæ‰€ä»¥è¦ç©ºé—´ç»Ÿè®¡
å› ä¸ºxåº”è¯¥æ˜¯åœ°åŒºçš„identityï¼Œå¦‚æœè¶Šé«˜è¯´æ˜æœ‰å½±å“
ä¸‰å¼ æ™®æŸ¥è¡¨LSOAç»Ÿè®¡+
```{r}
London_lsoa_sf
```

```{r}
wards_levels <- wards %>% st_drop_geometry() %>% dplyr::select(starts_with("LEVEL"))

pairs(wards_levels)
correlations <- cor(wards_levels)
corrplot(correlations, method = "square", diag = FALSE, tl.col = "black")
```

## 3.2 ğŸ’ª Spatial Inequality

### ğŸŒ¹3.2.1 Basic Work

#### 1) Spatial Inequality Measurement


#### 2) Map Plot Template

##### â‘   London Basemap

- Create bounding box according to the Greater London boundary
**æŠŠè·å–è¾¹ç•Œçš„London_neighborhoods_sfæ•°æ®æ¢æˆLSOAé‚£ä¸ªä»¥å…é¡ºåºé”™ä¹±**
```{r eval=FALSE}
# get the key
APIKey <-  "fb69e364-41da-4456-89d6-e775f32a8076"
register_stadiamaps(key = APIKey, write = TRUE)

London_plot_bbox <- st_bbox(London_neighborhoods_sf)
names(London_plot_bbox) <- c("left", "bottom", "right", "top")

basemap_London <- get_stadiamap(London_plot_bbox, maptype = "stamen_toner_lite", 
                                source = "stadia", zoom = 12)
basemap_London <- ggmap(basemap_London) +
                       theme(line = element_blank(),
                             rect = element_blank(),
                             axis.title=element_blank(),
                             axis.text=element_blank())
                 
London_basemap_plot<- ggplot() +
                      annotation_custom(ggplotGrob(basemap_London), 
                                xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf) +
                      theme(rect = element_blank())

London_basemap_plot
```

```{r echo=FALSE}
# saveRDS(London_plot_bbox, "RDS_data/London_plot_bbox.rds")
London_plot_bbox <- readRDS( "RDS_data/London_plot_bbox.rds")

# saveRDS(London_basemap_plot, "RDS_data/London_basemap_plot.rds")
London_basemap_plot <- readRDS( "RDS_data/London_basemap_plot.rds")
```


##### â‘¡ Basic Map Style (ä¸çŸ¥é“èƒ½ä¸èƒ½åˆå¹¶)

### ğŸŒ¹3.2.2 Spatial Data Visualization
#### 1) Stop-and-Search Heatmap
- tibbleçš„ç©ºé—´æ•°æ®è½¬æ¢
```{r}
# å°† convert London_SS_tibble to simple feature
London_SS_tibble$longitude <- as.numeric(London_SS_tibble$longitude)
London_SS_tibble$latitude <- as.numeric(London_SS_tibble$latitude)
London_SS_df <- as.data.frame(London_SS_tibble)
London_SS_sf <- st_as_sf(London_SS_df, coords = c("longitude", "latitude"), 
                         crs = st_crs(4326))

# add the coordinates into sf dataframe
coords <- st_coordinates(London_SS_sf)
London_SS_sf$longitude <- coords[, 'X']
London_SS_sf$latitude <- coords[, 'Y'] 
```

```{r eval=FALSE, fig.height=12, fig.width=15}

# 2D kernel density estimates were calculated using the stat_density2d() function in ggplot2, which automatically selects the bandwidth based on the standard deviation of the data and the number of data points.

SS_heatmap <- ggplot() +
  annotation_custom(ggplotGrob(London_basemap_plot), 
                    xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf) +
  labs(x ='', y ='', title = "Stop-and-search Records Heatmap in London") + 
  stat_density2d(data = London_SS_sf, aes(x=longitude, y=latitude,
                 fill=after_stat(level), alpha=after_stat(level)),
                 geom="polygon", adjust = 2) +  # bandwidth_size
  scale_alpha_continuous(range=c(0.25,0.65)) +
  scale_fill_gradientn(colours=rev(brewer.pal(7, "Spectral"))) +
  guides(fill=guide_legend("S&S Density"), alpha = "none") +
  geom_sf(data = London_SS_sf, color = 'black', size = 1.5, alpha = 0.3) +
  geom_sf(data = London_neighborhoods_sf, color = "black", 
          fill = NA, alpha = 0.8, size = 1) +
  coord_sf(xlim = London_plot_bbox[c(1,3)], ylim = London_plot_bbox[c(2,4)]) +
  theme(plot.title = element_text(size =35, hjust = 0.5, vjust = 1, face = "bold"),
        plot.margin = margin(t = 0.6, r = -12, 
                             b = 0, l = -12.5, "cm"),,
        legend.title = element_text(size = 25, face ='bold'),
        legend.position = c(0.9, 0.2),
        legend.key.size = unit(1.2, "cm"),
        legend.text = element_text(size = 22),
        legend.margin = margin(0, 2, 0, 2, "cm"),
        line = element_blank(), 
        rect = element_blank(), 
        axis.text=element_blank(),
        axis.title=element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
        annotation_scale(location = "bl", line_width = 0.28,
                         pad_x = unit(0.025, "npc"), pad_y = unit(0.03, "npc"), 
                         height = unit(0.35, "cm"), text_cex = 2) + 
        annotation_north_arrow(location = "bl", which_north = "true", 
                               pad_x = unit(0.08, "npc"), pad_y = unit(0.08, "npc"),
                               height = unit(2.5, "cm"), width = unit(2, "cm")) 
```

```{r echo=FALSE, eval=FALSE, fig.height=12, fig.width=15}
# saveRDS(SS_heatmap, "RDS_data/SS_heatmap.rds")
SS_heatmap <- readRDS( "RDS_data/SS_heatmap.rds")
SS_heatmap
```

#### 2) Spatial Inequality Distribution

### ğŸŒ¹3.2.3 Regression Analysis and Comparison

#### 1) Multiple Linear Regression


**OLSå›å½’**
```{r}
# ä½¿ç”¨lmå‡½æ•°è¿›è¡ŒOLSå›å½’åˆ†æ
model <- lm(y ~ x1 + x2, data = data)

# æŸ¥çœ‹å›å½’ç»“æœæ‘˜è¦
summary(model)

# è¿›è¡Œæ¨¡å‹è¯Šæ–­ï¼Œæ¯”å¦‚ç”»å‡ºæ®‹å·®å›¾
plot(model)
```


#### 2) Geographically Weighted Regression

(å˜ç³»æ•°)
```{r}
library(spgwr)

# å‡è®¾ä½ æœ‰ä¸€ä¸ªç©ºé—´ç‚¹æ•°æ®æ¡†dfï¼ŒåŒ…å«åæ ‡å’Œå…¶ä»–å˜é‡
# df <- data.frame(lon = ..., lat = ..., var1 = ..., var2 = ..., ...)

# å°†æ•°æ®æ¡†è½¬æ¢ä¸ºç©ºé—´ç‚¹å¯¹è±¡
coordinates(df) <- ~ lon + lat

# è¿›è¡ŒGWRï¼Œä½¿ç”¨var1ä½œä¸ºå› å˜é‡ï¼Œvar2ä½œä¸ºè‡ªå˜é‡
# è¿™é‡Œçš„bwæ˜¯å¸¦å®½ï¼Œå¯ä»¥é€šè¿‡gwr.selå‡½æ•°é€‰æ‹©æœ€ä¼˜å¸¦å®½
bw <- gwr.sel(var1 ~ var2, data = df, coords = cbind(df$lon, df$lat))
gwr_model <- gwr(var1 ~ var2, data = df, coords = cbind(df$lon, df$lat), bandwidth = bw)

# æŸ¥çœ‹GWRæ¨¡å‹çš„ç»“æœ
print(gwr_model)

# å¦‚æœéœ€è¦ï¼Œä¹Ÿå¯ä»¥è¿›è¡Œæ¨¡å‹çš„è¯Šæ–­å’Œå¯è§†åŒ–

```

## 3.3 ğŸ’ª Neighborhood Priority

### ğŸŒ¹3.3.1 Basic Work
#### 1) Neighborhood Information Collection
##### â‘  Neighborhood List
æ ¹æ®PFAå¯¹åº”neighborhood
```{r}
# I get the lists of neighborhoods of different police force areas in Greater London, containing Metropolitan and City of London. The total number of neighborhoods in Greater London is 680.
London_neighborhoods_tibble <- tibble()

for (PFA in London_PFAs){
    # è·å–ä¸åŒcountyçš„neighborhoodçš„url
    neighborhood_url <- sprintf("https://data.police.uk/api/%s/neighbourhoods", PFA)
    r <- GET(neighborhood_url)
    neighborhood_json <- httr::content(r, "parsed")     # parse the content returned from our GET request

    # ä½¿ç”¨ lapply å‡½æ•°, å…³è”neighbourhoodå¯¹åº”çš„PFA
    neighborhood_json <- lapply(neighborhood_json, function(x) {
      x$PFA_name <- PFA
      return(x)
    })

    # æ¸…é™¤å†…å±‚åµŒå¥—åˆ—è¡¨ ä½†è¦æ³¨æ„è¿™æ˜¯ä¸€ä¸ªåˆ—è¡¨æ˜¯ä¸€è¡Œï¼Œå¦‚æœå’Œå¦ä¸€ä¸ªå¿çš„å…ƒç´ rbind,æ˜¯æ‹¥æœ‰293åˆ—çš„ä¸€è¡Œå’Œæ‹¥æœ‰56åˆ—çš„ä¸€è¡Œç›¸äº’åˆå¹¶ï¼Œåˆ™åé¢ä¸€ä¸ªå¿çš„å…ƒç´ è¢«å¼ºè¡Œå¡«å……åˆ°293åˆ—ï¼ˆæœ‰å¾ˆå¤šå¿æ•°æ®è‡ªåŠ¨é‡å¤ï¼‰,åˆå¹¶å586åˆ—
    neighborhood_list <- lapply(neighborhood_json, unlist)

    # è½¬æ¢æˆtibble, ä½¿ç”¨ lapply è½¬æ¢æ¯ä¸ªå…ƒç´ ä¸º data.frameï¼Œç„¶åç”¨ do.call rbind åˆ°ä¸€èµ·
    neighborhood_tibble <- neighborhood_list %>% 
    lapply(function(x) as.data.frame(t(as.data.frame(x)))) %>% 
    do.call(rbind, .) %>% 
    as_tibble()

    # æ›´æ”¹åˆ—å
    neighborhood_tibble <- neighborhood_tibble %>% 
       rename(neigh_id = id, neigh_name = name)

    # åˆå¹¶ä¸åŒcountyçš„neighborhoodä¿¡æ¯
    London_neighborhoods_tibble <- rbind(London_neighborhoods_tibble, neighborhood_tibble)
}

```

**ä¸ºneighborhoodå…³è”ç›¸åº”çš„police force(æ ¹æ®å‰é¢ç®€åŒ–)**
```{r}
# è½¬æ¢æˆtibble, ä½¿ç”¨ lapply è½¬æ¢æ¯ä¸ªå…ƒç´ ä¸º data.frameï¼Œç„¶åç”¨ do.call rbind åˆ°ä¸€èµ·
force_tibble <- force_list %>% 
lapply(function(x) as.data.frame(t(as.data.frame(x)))) %>% 
do.call(rbind, .) %>% 
as_tibble()

# ä¸ºtibbleåˆ›å»ºç©ºç™½çš„forceæ–°åˆ—
London_neighborhoods_tibble$force <- NA

for (PFA in London_PFAs){
    # æ ¹æ®PFAå’Œpolice force nameåœ¨londonçš„å¯¹åº”å…³ç³»è¿›è¡Œèµ‹å€¼
    London_neighborhoods_tibble[London_neighborhoods_tibble$PFA_name == PFA, "force"] <- 
      force_tibble[force_tibble$id == PFA, "name"]
}
```

##### â‘  Neighborhood Boundaries
Crime type Priorityæ€ä¹ˆè§£é‡Šï¼Œæ€ä¹ˆå…³è”åˆ°object of searchå’Œtextä¸Š

ä¸ºäº†åç»­ç»˜åˆ¶åœ°å›¾ï¼Œéœ€è¦å°†neighborhood boundariesæ•°æ®è½¬æ¢æˆsfæ•°æ®éœ€è¦çš„geometryæ ¼å¼ï¼Œè¿™è¾¹å¯ä»¥ç€é‡è®²ä¸€ä¸‹POLYGONç±»å‹çš„è¾¹ç•Œåæ ‡æ•°æ®æ˜¯æ€ä¹ˆå­˜å‚¨çš„
è€—æ—¶ï¼š4min, 23:55-00:00
```{r eval=FALSE}
# ä¸ºtibbleåˆ›å»ºç©ºç™½çš„geometryæ–°åˆ—
London_neighborhoods_tibble$geometry <- NA

for (neigh_id in London_neighborhoods_tibble$neigh_id){
    PFA <- London_neighborhoods_tibble[London_neighborhoods_tibble$neigh_id == neigh_id, "PFA_name"][[1]]
    neigh_boundary_url <- sprintf("https://data.police.uk/api/%s/%s/boundary", PFA, neigh_id)
    r <- GET(neigh_boundary_url)
    neigh_boundary_json <- httr::content(r, "parsed")     # parse the content returned from our GET request
    
    # å°†neighborhood boundary çš„åæ ‡è½¬åŒ–æˆPOLYGONå½¢å¼
      # é¦–å…ˆå»é™¤åµŒå¥—åˆ—è¡¨
    neigh_boundary_list <- neigh_boundary_json %>% lapply(unlist) %>% 
      # å…¶æ¬¡å»é™¤å‘é‡çš„åå­—è½¬åŒ–ä¸ºçº¯numeric
    lapply(unname) %>% lapply(as.numeric) %>% 
      # å°†åˆ—è¡¨è½¬æ¢ä¸ºç¬¬ä¸€åˆ—ä¸ºç»´åº¦ï¼Œç¬¬äºŒåˆ—ä¸ºç»åº¦çš„çŸ©é˜µï¼Œæœ€åæ•´ä½“è½¬æ¢æˆä¸€ä¸ªåˆ—è¡¨
    do.call(rbind, .) %>% list()

    # å¯¹æ¢boundaryç‚¹é›†çš„ç»çº¬åº¦åæ ‡æ’åˆ—é¡ºåº
    neigh_boundary_list[[1]] <- neigh_boundary_list[[1]][, c(2, 1)]
      # åˆ›å»ºä¸€ä¸ªç®€å•çš„å¤šè¾¹å½¢,å¹¶è½¬æ¢ä¸ºç”¨äºå­˜å‚¨å‡ ä½•ä¿¡æ¯çš„ç‰¹æ®Šåˆ—ç±»å‹sfc, whiché€‚åˆåµŒå…¥åˆ° tibble æˆ– data.frameä¸­
    neigh_boundary_polygon <- neigh_boundary_list %>% st_polygon() %>% st_sfc()
    London_neighborhoods_tibble[London_neighborhoods_tibble$neigh_id == neigh_id, "geometry"][[1]] <- neigh_boundary_polygon
}

London_neighborhoods_tibble
```

```{r echo=FALSE, paged.print=TRUE}
# saveRDS(London_neighborhoods_tibble, "RDS_data/London_neighborhoods_tibble.rds")
London_neighborhoods_tibble<- readRDS( "RDS_data/London_neighborhoods_tibble.rds")
London_neighborhoods_tibble
```

è½¬åŒ–ä¸ºsfæ•°æ®
```{r}
# è½¬æ¢ tibble ä¸º sf å¯¹è±¡
London_neighborhoods_sf <- st_as_sf(London_neighborhoods_tibble, sf_column_name = "geometry", crs = 4326)
# å°† sf å¯¹è±¡å†™å…¥ Shapefile
st_write(London_neighborhoods_sf, "All_data/London_neighborhoods/London_neighborhoods_sf.shp", append = FALSE)
```

#### 2) Map Plot template

ç°åœ¨è¿™é‡Œåˆ¶ä½œä¸€ä¸ªplot template, è‡ªå®šä¹‰è‰²å½©å¯è§†åŒ–æ•°æ®(è¿™ä¸ªç›¸å…³æ€§å†é«˜å¿…ç„¶æœ‰ä¸å¥½çš„åˆ†ç±»ï¼Œå¯ä»¥å†ä¸€å¼ å›¾side-by-sideï¼šé¢œè‰²+å¤§å°)
```{r}
library(biscale)
```

```{r eval=FALSE, fig.height=12, fig.width=15}
Bivariate_map_plot <- function(title, legend_loc, fill_layer){
  Bivariate_map <- 
  London_basemap_plot +
  labs(x ='', y ='', title = title) +
  geom_sf(data = London_neighborhoods_sf, inherit.aes = FALSE, aes(fill = fill_layer), color = 'black', size = 1.5, alpha = 1) +
  coord_sf(xlim = London_plot_bbox[c(1,3)], ylim = London_plot_bbox[c(2,4)]) +
  theme(plot.title = element_text(size =35, hjust = 0.5, vjust = 1, face = "bold"),
        plot.margin = margin(t = 0.6, r = -12, 
                             b = 0, l = -12.5, "cm"),
        legend.title = element_text(size = 25, face ='bold'),
        legend.position = legend_loc,
        legend.key.size = unit(1.2, "cm"),
        legend.text = element_text(size = 22),
        legend.margin = margin(0, 2, 0, 2, "cm"),
        line = element_blank(), 
        rect = element_blank(), 
        axis.text=element_blank(),
        axis.title=element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
        annotation_scale(location = "bl", line_width = 0.2,
                         pad_x = unit(0.025, "npc"), pad_y = unit(0.03, "npc"), 
                         height = unit(0.32, "cm"), text_cex = 1.5) + 
        annotation_north_arrow(location = "bl", which_north = "true", 
                               pad_x = unit(0.08, "npc"), pad_y = unit(0.08, "npc"),
                               height = unit(2, "cm"), width = unit(1.5, "cm"))
  return(Bivariate_map)
}
```

### ğŸŒ¹3.3.2 Neighborhood Priority
å¯ä»¥å…ˆè€ƒè™‘æ—¶é—´åœ¨202311å¹´å†…çš„ï¼Œå¦‚æœå¤§éƒ¨åˆ†æ²¡æœ‰å†è€ƒè™‘å…¨éƒ¨çš„priority

**æ³¨æ„ï¼šå½“èµ‹å€¼ç»™tibbleçš„åˆ—å€¼æ˜¯å¤æ‚æ•°æ®ç»“æ„æ—¶ï¼Œç”¨[[1]]æ‰å¯ä»¥**
**åç»­æ–‡æœ¬åˆ†ææŠŠdate, issue_textå˜æˆdate, issueï¼ˆå‡ ç±»ï¼‰å’Œ date, s&s åšæ—¶é—´çº¿å¯¹æ¯”ï¼Œå‚è§ä¹‹å‰çš„semianr code æœ‰ä¸€ä¸ªç±»ä¼¼çš„ï¼**

#### 1) Issue Texts Collection
è·å–priority_infoï¼ˆæ‰€æœ‰æ—¥æœŸ+æ–‡æœ¬ï¼‰
- é€šè¿‡ä»€ä¹ˆä»€ä¹ˆapiè·å–
```{r eval=FALSE}
# create a empty column to save spatial info for London_neighborhoods_tibble
London_neighborhoods_tibble$priority_info <- NA

for (neigh_id in London_neighborhoods_tibble$neigh_id){
    PFA <- London_neighborhoods_tibble[London_neighborhoods_tibble$neigh_id == neigh_id, "PFA_name"][[1]]
    neigh_priority_url <- sprintf("https://data.police.uk/api/%s/%s/priorities", PFA, neigh_id)
    r <- GET(neigh_priority_url)
    neigh_priority_json <- httr::content(r, "parsed") # parse the content returned from our GET request
    
    priority_info_list <- list()
    
    for (priority in neigh_priority_json){
      priority_date <- priority$`issue-date`  
      priority_info <- list(date = priority_date, issue_text = priority$issue)
      priority_info_list <- c(priority_info_list, list(priority_info))
    }
    if (length(priority_info_list) != 0){
      London_neighborhoods_tibble[London_neighborhoods_tibble$neigh_id == neigh_id, "priority_info"][[1]] <- list(priority_info_list)
    }
}

London_neighborhoods_tibble
```

```{r echo=FALSE, paged.print=TRUE}
# saveRDS(London_neighborhoods_tibble, "RDS_data/London_neighborhoods_tibble_1.rds")
London_neighborhoods_tibble<- readRDS("RDS_data/London_neighborhoods_tibble_1.rds")
London_neighborhoods_tibble
```

```{r}
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
```

#### 2) Texual Keywords Extraction

##### â‘   Text Combination 

å› ä¸ºåŸæ•°æ®æ˜¯åˆ†å¹´æœˆæ—¥æ—¶é—´åˆ†å¼€ç»Ÿè®¡çš„ï¼Œä¸ºäº†æ•´ä½“ç»Ÿè®¡priorityï¼Œé¦–å…ˆåˆå¹¶Text
all year texts
å†™ä¸€ä¸ªå‘é‡priority_docï¼Œå‘é‡é‡Œæ˜¯æ¯ä¸ªneighborhoodçš„å†å¹´priorityåˆå¹¶æ–‡æœ¬ï¼Œåå­—æ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰é‚»idé‡Œçš„å‘é‡
2minï¼Œåˆå¹¶åŒä¸€neighborhoodçš„æ–‡æœ¬
```{r eval=FALSE}
priority_doc <- c()
for (neigh_id in London_neighborhoods_tibble$neigh_id){
  issue_text_all <- c()
  
  neigh_priority <- London_neighborhoods_tibble[London_neighborhoods_tibble$neigh_id == neigh_id, "priority_info"][[1]]
  
  for (priority_date in neigh_priority[[1]]){
    issue_text <- priority_date$issue_text
    issue_text_all <- c(issue_text_all, issue_text)
  }
  neigh_combined_text <- paste(issue_text_all, collapse = " ")
  names(neigh_combined_text) <- neigh_id
  priority_doc <- c(priority_doc, neigh_combined_text)
}

head(priority_doc, n = 2L)
```

```{r echo=FALSE}
# saveRDS(priority_doc, "RDS_data/priority_doc.rds")
priority_doc <- readRDS("RDS_data/priority_doc.rds")
# writeLines(priority_doc, "priority_doc.txt")
head(priority_doc, n = 2L)
```

##### â‘¡ Tokenization and Cleaning
åˆ›å»ºdfmç»Ÿè®¡åˆ†æå…³é”®è¯
æ ‡å‡†åŒ–ï¼ˆNormalizationï¼‰ï¼šè¿™ä¸€æ­¥éª¤åŒ…æ‹¬å°†æ‰€æœ‰tokensè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼Œä»¥å‡å°‘æ•°æ®çš„å¤æ‚æ€§ã€‚å¸¸è§çš„æ ‡å‡†åŒ–æŠ€æœ¯åŒ…æ‹¬å°å†™åŒ–ï¼ˆè½¬æ¢ä¸ºå°å†™ï¼‰ã€è¯å¹²æå–ï¼ˆstemmingï¼Œå‡å°‘å•è¯åˆ°è¯å¹²å½¢å¼ï¼‰ã€è¯å½¢è¿˜åŸï¼ˆlemmatizationï¼Œå°†å•è¯è¿˜åŸåˆ°å…¶è¯å…¸å½¢å¼ï¼‰ã€‚
åˆ†è¯ï¼ˆTokenizationï¼‰ï¼šè¿™æ˜¯å°†æ–‡æœ¬åˆ†å‰²æˆå•ç‹¬tokensï¼ˆå¦‚å•è¯ã€çŸ­è¯­æˆ–å…¶ä»–ç¬¦å·ï¼‰çš„è¿‡ç¨‹ã€‚ä¾‹å¦‚ï¼Œå¥å­ "Natural language processing is interesting." å¯ä»¥è¢«åˆ†è¯ä¸º "Natural", "language", "processing", "is", "interesting", å’Œ "."ã€‚

æ–‡æœ¬æ¸…æ´—ï¼šåœ¨åˆ†è¯ä¹‹åï¼Œé€šå¸¸éœ€è¦æ¸…æ´—æ–‡æœ¬ï¼Œç§»é™¤å™ªå£°æ•°æ®ï¼Œå¦‚æ ‡ç‚¹ç¬¦å·ã€ç‰¹æ®Šå­—ç¬¦ã€åœç”¨è¯ï¼ˆstop wordsï¼Œå¦‚"and", "the", "is" ç­‰å¸¸è§ä½†é€šå¸¸ä¸å«ä¿¡æ¯é‡çš„å•è¯ï¼‰ã€‚

```{r paged.print=TRUE}
priority_docvars <- London_neighborhoods_tibble %>% dplyr::select(neigh_id, neigh_name, PFA_name, force) %>%
                    mutate(characters = str_count(priority_doc)) %>% 
                    as.data.frame()

priority_corpus <- corpus(priority_doc,
                       docvars = priority_docvars)

priority_corpus                      
docvars(priority_corpus)
```

æ¸…ç†æ–‡æœ¬ç‰¹å¾ï¼Œè½¬åŒ–æˆdfm
```{r}
# transform corpus to document-feature matrix
text_mining <- function(corpus) {
  
    corpus_token <- corpus %>% 
    tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
    tokens_remove(stopwords("en")) %>%  # remove usual unnecessary words in English
# Whole Word Matching
      # Remove tokens that do not contain letters (pure numbers, etc.)
    tokens_remove(pattern = "\\b[^a-zA-Z]+\\b", valuetype = "regex") %>%  
      # Remove tokens containing numbers, regardless of position
    tokens_remove(pattern = "[0-9]+", valuetype = "regex") %>%  
      # Remove tokens containing non-word characters at the beginning and end, such as "-", "@"
    tokens_remove(pattern = "^\\W+|\\W+$", valuetype = "regex") %>% 
      # Remove tokens containing Chinese characters
    tokens_remove(pattern = "[\\u4E00-\\u9FFF]", valuetype = "regex") %>% 
      # Remove tokens consisting of 1 or 2 letters, which are generally not content words
    tokens_remove(pattern = "\\b[a-zA-Z]{1,2}\\b", valuetype = "regex") %>%  
    tokens_tolower()
    # steming the word to the basic form, like running and ran <- run
    corpus_token_stemed <- tokens_wordstem(corpus_token) 
    dfm <- corpus_token_stemed %>% dfm() %>% dfm_trim(min_termfreq = 5) # deletes all terms which are not in the corpus at least fifth, so that we can filter some address or people names
    result <- list(dfm, corpus_token, corpus_token_stemed)
    return(result)
}
   
```

```{r eval=FALSE}
# Get dfm, tokens and stemmed tokens for all neighborhoods of all years 
result_all <- text_mining(priority_corpus)
priority_dfm <- result_all[[1]]
priority_token <- result_all[[2]]
priority_token_stemed <- result_all[[3]]

priority_dfm
```

```{r echo=FALSE}
# saveRDS(priority_token, "RDS_data/priority_token.rds")
priority_token<- readRDS("RDS_data/priority_token.rds")

# saveRDS(priority_token_stemed, "RDS_data/priority_token_stemed.rds")
priority_token_stemed<- readRDS("RDS_data/priority_token_stemed.rds")

# saveRDS(priority_dfm, "RDS_data/priority_dfm.rds")
priority_dfm<- readRDS("RDS_data/priority_dfm.rds")
priority_dfm
```

```{r eval=FALSE, include=FALSE}
priority_dfm_df <- convert(priority_dfm, to = "data.frame")
# Transpose matrix
priority_dfm_mat <- t(priority_dfm_df)
col_names <- priority_dfm_T[1, ]
priority_dfm_df_T <- as.data.frame(priority_dfm_mat)
colnames(priority_dfm_df_T) <- col_names
priority_dfm_df_T <- priority_dfm_df_T[-1, ]
# Write data frame into csv
write.csv(priority_dfm_df_T, "priority_dfm_T.csv", row.names = TRUE)
```

åˆ›å»ºä¸€ä¸ªæŸ¥æ‰¾è¡¨ï¼šå¯¹ä½ çš„æ–‡æœ¬æ•°æ®é›†è¿›è¡Œè¯å¹²æå–ã€‚åˆ›å»ºä¸€ä¸ªåŒ…å«åŸå§‹å•è¯å’Œå®ƒä»¬çš„è¯å¹²ç‰ˆæœ¬çš„æ˜ å°„ã€‚å°†è¿™ä¸ªæ˜ å°„ä¿å­˜ä¸ºæŸ¥æ‰¾è¡¨ã€‚åˆ›å»ºä¸€ä¸ªæŸ¥æ‰¾è¡¨ï¼Œæ ¹æ®stemmedåˆ—çš„å€¼åˆå¹¶originalåˆ—çš„å€¼ï¼Œå¹¶ä»¥é€—å·åˆ†éš”
tokens_wordstemå’ŒåŸå•è¯å¯¹ç…§è¡¨
This code creates a lookup table to make it easy to see which original words share the same stem.
```{r}
wordstem_lookup <- function(token, token_stemed){
  
  df_stemmed <- data.frame(original = unlist(token), 
                           stemmed = unlist(token_stemed))
  # keep only unique mappings
  df_unique <- df_stemmed[!duplicated(df_stemmed$original), ]
  
  # åˆ›å»ºä¸€ä¸ªæŸ¥æ‰¾è¡¨ï¼Œæ ¹æ®stemmedåˆ—çš„å€¼åˆå¹¶originalåˆ—çš„å€¼ï¼Œå¹¶ä»¥é€—å·åˆ†éš”ï¼š
  wordstem_lookup <- df_unique %>% 
    group_by(stemmed) %>%
    summarise(combined = toString(unique(original)))
  
  return(wordstem_lookup)
}

```

```{r eval=FALSE, paged.print=TRUE}
wordstem_lookup_list <- wordstem_lookup(priority_token, priority_token_stemed)
wordstem_lookup_list
```

```{r echo=FALSE, paged.print=TRUE}
# saveRDS(wordstem_lookup_list, "RDS_data/wordstem_lookup_list.rds")
wordstem_lookup_list<- readRDS("RDS_data/wordstem_lookup_list.rds")
wordstem_lookup_list
```

```{r eval=FALSE, include=FALSE}
# wordstem_lookup
write.csv(wordstem_lookup, "wordstem_lookup.csv", row.names = FALSE)
```

##### â‘¢ Priority Keywords Definition
**dfmè½¬æ¢æˆdataframe,å­˜å‚¨åˆ°æœ¬åœ°è¿›è¡Œè§‚å¯Ÿ,æå–å¹¶ç»Ÿè®¡ä¸»é¢˜è¯**
Convert dfm into dataframe, store it locally for observation, extract and count subject words
Crime Constitution
**é€šè¿‡è§‚å¯Ÿobject of searchçš„ç±»å‹ï¼Œæå–å‡ºä¸‰ç§ä¸»é¢˜è¯**
4å¼ å †å ä¸åˆ†å­å›¾ï¼Œä¸Šé¢ä¸¤ä¸ªåå­—type(å…ˆç»„åˆå®ƒä»¬å¹¶å–åï¼‰ï¼Œä¸‹é¢ä¸¤ä¸ªåå­—ç¨‹åº¦
Crime type:
object_of_searchï¼ˆ9ï¼‰, legislationï¼ˆ4ï¼‰

Crime severity (including mistake): 
outcomeï¼ˆ7ï¼‰, $removal_of_more_than_outer_clothingï¼ˆ2ï¼‰

éœ€è¦è‡ªå®šä¹‰çš„é¡¹ï¼šå›¾ä¾‹å‚æ•°ï¼ˆä½ç½®ï¼Œæ ‡ç­¾å¤§å°)ï¼Œæ ‡é¢˜å¤§å°
ä½ç½®å’Œé—´è·ï¼‰

- Plot Stacked Bar Chart for Proportions of Self-defined Ethnicity under Stop-and-search
```{r fig.width=18, fig.height=6}

object_of_search <- col_counts_df$object_of_search
legislation <- col_counts_df$legislation


outcome <- col_counts_df$outcome

# choose stacked bar
object_of_search_plot <- object_of_search %>% 
                         bar_plot(plot_type = "stacked",
                                  title = "", 
                                  legend_lab = "Object of Search")

# legislation_plot <- legislation %>% 
#                          bar_plot(plot_type = "stacked",
#                                   title = "", 
#                                   legend_lab = "Object of Search")

outcome_plot <- outcome %>% 
                         bar_plot(plot_type = "stacked",
                                  title = "", 
                                  legend_lab = "Object of Search")

identity_plot <- plot_grid(object_of_search_plot, outcome_plot, nrow = 1)
identity_plot

# final_identity_plot <- ggdraw() + 
#               draw_plot(identity_plot) +
#               draw_label('Pie Charts for Proportions of People with Different Identities under Stop-and-search', 
#                          fontface = 'bold', size = 32, x = 0.5, 
#                          vjust = -7.5, hjust = 0.5)
# final_identity_plot
```


```{r}
crime_keywords <- dictionary(list(ASB_keywords = c('violenc','damag','harass','distract', 'fight', 'combat', 'assault', 'graffiti', 'tension','speed','aggress', 'weapon', 'gang', 'knife', 'firework', 'children', 'women', 'girl', 'youth', 'femal', 'sexual', 'drinker', 'beggar'),
# P.S. speed: excess speed
                              
                              Drug_keywords = c('drug', 'deal', 'dealer', 'misus', 'abuse', 'cannabi', "nox", 'nitrous', 'oxid', 'substanc'),
# P.S. misus: misuse; NOx, oxid, nitrous: nitric oxide; canist: substanc: controlled substances(refer to drug)
                              
                              Theft_keywords = c('theft', 'steal', 'burglari', 'stolen', 'snatch', 'pickpocket', 'shoplift', 'fraud','tfmv', 'catalyt', 'bike', 'bicycl', 'keyless', 'parcel')))
# P.S. tfmv: theft from motor vehicles; Catalytic convertor theft
```

- Count the keywords in the neighborhood issue texts for all years and convert them into tibble
```{r}
priority_type <- priority_dfm %>% dfm_lookup(dictionary = crime_keywords) %>% 
                                     convert(to = "data.frame") %>% as_tibble()
```


### ğŸŒ¹3.2.2 Potential Bias Analysis

#### 1) Priority and Different S&S Bivariate Map
éœ€è¦ç€é‡ä»‹ç»ä¸€ä¸‹ Bivariate Mapçš„æ¦‚å¿µå°¤å…¶æ˜¯åé¢ç»˜å›¾çš„ç®—æ³•
##### â‘   å¯¹S&S dataè¿›è¡Œåˆ†ç±»
- æŒ‰ç…§åˆ—object_of_searchçš„å€¼å¯¹S&S dataçš„S&S typeè¿›è¡Œåˆ†ç±»ï¼Œå¹¶å­˜å‚¨åœ¨S_S_typeåˆ—å†…ã€‚è¿›ä¸€æ­¥å°†å…¶æŒ‰ç…§S&S typeåˆ†ä¸ºä¸‰ä»½æ•°æ®ä¾¿äºåç»­åˆ†æ
```{r eval=FALSE}
# The S&S type of S&S data is classified according to the value of column 'object_of_search' and stored in the column 'S_S_type'. It is further divided into three data according to S&S type to facilitate following analysis.

for (object in London_SS_sf$object_of_search) {
  if (object == "Controlled drugs") {
    London_SS_sf[London_SS_sf$object_of_search == object, "S_S_type"] <- "Drug"
  } else if (object == "Stolen goods") {
    London_SS_sf[London_SS_sf$object_of_search == object, "S_S_type"] <- "Theft"
  } else {
    London_SS_sf[London_SS_sf$object_of_search == object, "S_S_type"] <- "ASB"  # Anti-social Behaviour
  }
}

London_SS_ASB <- London_SS_sf %>% filter(S_S_type == "ASB") # 1805
                 
  
London_SS_Drug <- London_SS_sf %>% filter(S_S_type == "Drug") # 3794

London_SS_Theft <- London_SS_sf %>% filter(S_S_type == "Theft") # 1037
```

```{r echo=FALSE, paged.print=TRUE}
# saveRDS(London_SS_ASB, "RDS_data/London_SS_ASB.rds")
London_SS_ASB <- readRDS("RDS_data/London_SS_ASB.rds")

# saveRDS(London_SS_Drug, "RDS_data/London_SS_Drug.rds")
London_SS_Drug <- readRDS("RDS_data/London_SS_Drug.rds")

# saveRDS(London_SS_Theft, "RDS_data/London_SS_Theft.rds")
London_SS_Theft <- readRDS("RDS_data/London_SS_Theft.rds")
```

##### â‘¡ å¯¹S&S dataè¿›è¡Œåˆ†ç±»
ç©ºé—´å…³è”åˆ°neighborhood

**æ—¢ä¸Šæ¬¡ç”ŸæˆLondon_neighborhoods_sfå­˜åˆ°shpï¼Œè¯»å–**
```{r eval=FALSE, include=FALSE}
# download the neighborhood boundary data generated before
London_neighborhoods_sf <- read_sf(paste0(path_to_folder,"/All_data/London_neighborhoods/London_neighborhoods_sf.shp"))
```

ç”»bi_mapéœ€è¦æŠŠæ‰€æœ‰æ•°æ®æ”¾åˆ°ä¸€ä¸ªç©ºé—´æ•°æ®ä¸Šï¼Œä¸”æ¯ä¸€ä¸ªtypeéœ€è¦æ˜¯ä¸€åˆ—
```{r eval=FALSE}
  # left join the specific S&S type data (e.g. London_ASB_type) to the London_neighborhoods_sf with all information
neigh_spatial_join <- function(London_SS_type, type){
  neigh_SS_type <- London_neighborhoods_sf %>%
                st_join(London_SS_type, left = FALSE) %>%   
                group_by(neigh_id) %>%
                summarize(SS_count = n())
  
 # for loop the neigh_id of London_neighborhoods_sf, if the id of specific S&S type data is inside, create first time and update the specific column every time. Otherwise update the value with 0  
  for (neigh_ID in London_neighborhoods_sf$neigh_id){
    if (neigh_ID %in% neigh_SS_type$neigh_id){
      London_neighborhoods_sf[London_neighborhoods_sf$neigh_id == neigh_ID, 
                              sprintf("SS_%s_count", type)] <- 
        neigh_SS_type[neigh_SS_type$neigh_id == neigh_ID, "SS_count"][[1]]
    }
    else{London_neighborhoods_sf[London_neighborhoods_sf$neigh_id == neigh_ID, 
                                 sprintf("SS_%s_count", type)] <- 0}
  }
  return(London_neighborhoods_sf)
}

# è®¾ç½®ä¸€ä¸ªå‚æ•°typeï¼Œä¸åŒtypeå¯¹åº”è¯¥æ•°æ®çš„ä¸åŒå­—æ®µåçš„æ›´æ–°
London_neighborhoods_sf <- neigh_spatial_join(London_SS_ASB, "ASB")
London_neighborhoods_sf <- neigh_spatial_join(London_SS_Drug, "Drug")
London_neighborhoods_sf <- neigh_spatial_join(London_SS_Theft, "Theft")
London_neighborhoods_sf
```

```{r echo=FALSE, paged.print=TRUE}
# saveRDS(London_neighborhoods_sf, "RDS_data/London_neighborhoods_sf.rds")
London_neighborhoods_sf <- readRDS("RDS_data/London_neighborhoods_sf.rds")
head(London_neighborhoods_sf, n =2L)
```

```{r eval=FALSE}
# first transform into dataframe to for table joining, then connect neighborhood priority and London_neighborhoods_sf with different types of s&s counts
London_neighborhoods_sf <- London_neighborhoods_sf %>% as.data.frame() %>% 
                           inner_join(priority_type, by = c("neigh_id" = "doc_id")) %>% 
# calculate the bi_class of three S&S types separately
                           bi_class(x = SS_ASB_count, 
                                    y = ASB_keywords, 
                                    style = "jenks", dim = 3) %>%   
                           rename("ASB_bi_class" = "bi_class") %>% 

                           bi_class(x = SS_Drug_count, 
                                    y = Drug_keywords, 
                                    style = "jenks", dim = 3) %>%
                           rename("Drug_bi_class" = "bi_class") %>% 


                           bi_class(x = SS_Theft_count, 
                                    y = Theft_keywords, 
                                    style = "jenks", dim = 3) %>%
                           rename("Theft_bi_class" = "bi_class") %>%
# transform back to sf
                           st_as_sf(sf_column_name = "geometry", crs = st_crs(4326))
  
```

```{r echo=FALSE}
# saveRDS(London_neighborhoods_sf, "RDS_data/London_neighborhoods_sf1.rds")
London_neighborhoods_sf <- readRDS("RDS_data/London_neighborhoods_sf1.rds")
London_neighborhoods_sf
```

Anti-social Behavior 
Higher frequency of neighborhood priority
Higher incidence of Stop-and-search
```{r eval=FALSE, fig.height=11, fig.width=13}
# bi_theme()
ASB_bivariate <- Bivariate_map_plot(title = "", legend_loc = "", fill_layer = London_neighborhoods_sf$ASB_bi_class) +
                 bi_scale_fill(pal = "GrPink", dim = 3) + labs(caption = "(Anti-social Behavior)") +
                 theme(plot.caption = element_text(hjust = 0.5, vjust = 1.8, size = 20))

Drug_bivariate <- Bivariate_map_plot(title = "", legend_loc = "", fill_layer = London_neighborhoods_sf$Drug_bi_class) +
                  bi_scale_fill(pal = "GrPink", dim = 3) + labs(caption = "(Controlled Drug)") +
                  theme(plot.caption = element_text(hjust = 0.5, vjust = 1.8, size = 20))

Theft_bivariate <- Bivariate_map_plot(title = "", legend_loc = "", fill_layer = London_neighborhoods_sf$Theft_bi_class) +
                   bi_scale_fill(pal = "GrPink", dim = 3) + labs(caption = "(Theft)") +
                   theme(plot.caption = element_text(hjust = 0.5, vjust = 1.8, size = 20))

# side by side
combined_plot_bivariate <- plot_grid(ASB_bivariate, Drug_bivariate, Theft_bivariate, ncol = 2)

final_plot_bivariate <- ggdraw() +
              draw_plot(combined_plot_bivariate) +
              draw_label('Bivariate Map of Stop-and-Search Types and Neighborhood Priority in London', fontface = 'bold', size = 25, x = 0.5, vjust = -19, hjust = 0.5)

legend <- bi_legend(pal = "GrPink",
                    dim = 3,
                    xlab = "Higher Neighborhood Priority",
                    ylab = "Higher Stop-And-Search",
                    size = 20)

# combine map with legend
final_plot_bivariate <- ggdraw() +
  draw_plot(final_plot_bivariate, 0, 0, 1, 1) +
  draw_plot(legend, 0.65, 0.12, 0.2, 0.2, scale = 2)  # left, bottom, right, top

final_plot_bivariate
```

```{r echo=FALSE, fig.height=11, fig.width=13}
# saveRDS(final_plot_bivariate, "RDS_data/final_plot_bivariate.rds")
final_plot_bivariate <- readRDS("RDS_data/final_plot_bivariate.rds")
final_plot_bivariate
```
#### 2) ğŸ˜‚ Priority in Research Period
æ—¶åºå…±ç°å›¾ï¼Ÿ
202311
ç›´æ¥å†™ä¸€ä¸ªdocvarsï¼Œåé¢å»ºcorpusçš„æ—¶å€™åªéœ€å†åŠ ä¸€åˆ—å­—æ•°ï¼Œåˆ—åŒ…å«ï¼›date, neigh_id, neigh_name, pfa, force, priority_text
```{r eval=FALSE}

# doc and docvars for corpus
priority_doc_202311 <- c()
priority_docvars_202311 <- data_frame()

for (neigh_ID in London_neighborhoods_tibble$neigh_ID){
   # get the detailed information of neighborhoods for docvars data
  neigh_name <- London_neighborhoods_tibble %>% dplyr::filter(neigh_ID == neigh_ID) %>% select(neigh_name) %>% pull()
  PFA_name <- London_neighborhoods_tibble %>% dplyr::filter(neigh_ID == neigh_ID) %>% select(PFA_name) %>% pull()
  force <- London_neighborhoods_tibble %>% dplyr::filter(neigh_ID == neigh_ID) %>% select(force) %>% pull()
  neigh_priority <- London_neighborhoods_tibble[London_neighborhoods_tibble$neigh_ID == neigh_ID, "priority_info"][[1]]
  
  for (priority_date in neigh_priority[[1]]){

    issue_date <- priority_date$date %>% ymd_hms()
    # Parse datetime string and extract year and month
    issue_ym <- format(issue_date, "%Y-%m")
    
    if (issue_ym == "2023-11"){
      
        issue_text <- priority_date$issue_text
        
        doc_name <- paste0(neigh_ID, "_", issue_date)
      
        if (doc_name %in% names(priority_doc_202311)){ 
        # if doc_name already exist then paste the new text to the former text and update the corresponding row in priority_doc_202311
          # combine text
          priority_doc_202311[doc_name] <- paste(priority_doc_202311[doc_name], issue_text)
          
          # update the text length in priority_docvars_202311
          priority_docvars_202311[priority_docvars_202311$neigh_ID == neigh_ID & priority_docvars_202311$priority_date == issue_date, "characters"] <- str_count(priority_doc_202311[doc_name])
        }
        
        else{
         # if doc_name doesn't exist then add a new row in priority_doc_202311
          priority_doc_202311[doc_name] <- issue_text

          neigh_date_priority_info <- data_frame("neigh_ID" = neigh_ID, 
                                                 "neigh_name" = neigh_name,
                                                 "priority_date" = issue_date,
                                                 "PFA_name" = PFA_name, "force" = force,
                                                 "characters" = str_count(priority_doc_202311[doc_name]))
          # add this row to priority_docvars_202311
          priority_docvars_202311 <- rbind(priority_docvars_202311, neigh_date_priority_info)
      }
    }
  }
}

head(priority_doc_202311, n = 2L)
```

```{r echo=FALSE}
# saveRDS(priority_doc_202311, "RDS_data/priority_doc_202311.rds")
priority_doc_202311<- readRDS("RDS_data/priority_doc_202311.rds")
head(priority_doc_202311, n = 2L)
# saveRDS(priority_docvars_202311, "RDS_data/priority_docvars_202311.rds")
priority_docvars_202311<- readRDS("RDS_data/priority_docvars_202311.rds")
```

```{r eval=FALSE}
# create corpus
priority_corpus_202311 <- corpus(priority_doc_202311,
                       docvars = priority_docvars_202311)

docvars(priority_corpus_202311)

# create and clean dfm
priority_dfm_202311 <- text_mining(priority_corpus_202311)[[1]]
priority_dfm_202311

# Check the number of neighborhoods that have S&S priority in Dec.2023: 103
length(unique(priority_dfm_202311$neigh_id))
```
```{r echo=FALSE}
# saveRDS(priority_dfm_202311, "RDS_data/priority_dfm_202311.rds")
priority_dfm_202311<- readRDS("RDS_data/priority_dfm_202311.rds")
priority_dfm_202311
```

 - Convert dfm to tibble for following analysis
```{r eval=FALSE}
# convert dfm into tibble
neigh_priority_key_202311 <- priority_dfm_202311 %>% 
                           dfm_lookup(dictionary = crime_keywords) %>% 
                           convert(to = "data.frame") %>% as_tibble()
neigh_priority_key_202311

# extract neigh_id and priority_date from doc_id
neigh_id <- unlist(lapply(neigh_priority_key_202311$doc_id, 
                          function(x) strsplit(x, "_")[[1]][1]))

priority_date <- unlist(lapply(neigh_priority_key_202311$doc_id, 
                          function(x) strsplit(x, "_")[[1]][2]))
# convert chr to standard date format
priority_date <- as.Date(unlist(lapply(priority_date, function(x) as.Date(x))))

neigh_priority_key_202311$neigh_id <- neigh_id
neigh_priority_key_202311$priority_date <- priority_date

```

```{r echo=FALSE, paged.print=TRUE}
# saveRDS(neigh_priority_key_202311, "RDS_data/neigh_priority_key_202311.rds")
neigh_priority_key_202311<- readRDS("RDS_data/neigh_priority_key_202311.rds")
neigh_priority_key_202311
```

3 åšæ—¶åºå›¾ä¸s&så…±ç°ï¼š
text -> keyword -> s&s type
103ä¸ªneighborhoodåˆ†åˆ«æ˜¯åœ¨å“ªå¤©å‡ºç°ä»€ä¹ˆtypeï¼Œæ˜¯å¦è·Ÿå‘å¸ƒåå½“æœˆæˆ–ä¸‹ä¸ªæœˆçš„æŸç±»æœæŸ¥çš„å¢é•¿é«˜åº¦ç›¸å…³ï¼ˆæœ‰å“ªäº›neighborhoodç›¸å…³ï¼‰
é«˜åº¦ç›¸å…³çš„è¡¡é‡æ–¹æ³•ï¼šissueå‡ºç°çš„æ—¶é—´èŠ‚ç‚¹ä¹‹åçš„æŸç±»æœæŸ¥çš„æ•°é‡æ¯”è¯¥æœˆä¹‹å‰å¤šï¼ˆå¢é•¿ç‡å¾ˆå¤§ï¼‰-->ç­›é€‰æ’åå‰6ï¼ˆå¾…å®šï¼‰çš„neighborhoodåšâ‘¡ æ—¶åºå›¾
æ—¶åºå›¾æ„æ€ï¼šxè½´ä¸º11æœˆçš„æ—¶åºï¼ˆ30å¤©ï¼‰ï¼Œyè½´ä¸ºs&sæ•°ç›®ï¼ŒæŒ‰çŠ¯ç½ªç±»å‹åˆ†å­å›¾åˆ†å‡º3å¼ å­å›¾ï¼Œæ ‡å‡ºå…±ç°æ—¥æœŸçš„ç‚¹ï¼ˆç‚¹çš„å¤§å°æ˜¯å…³é”®è¯å‡ºç°æ•°é‡
ï¼‰ï¼Œå¯¹æ¯”ä¸åŒneighborhoodä¸åŒç±»å‹çš„çŠ¯ç½ªé—®é¢˜å¯¹æœæŸ¥å¢é•¿çš„å½±å“
éœ€è¦ä¸€ä¸ªè¡¨æ ¼ï¼šneighborhoodidï¼Œ11æœˆæ‰€æœ‰æ—¥ï¼ˆxè½´30ä¸ªç‚¹ï¼‰ï¼ˆä»ä¸€ä¸ªæœ‰æ‰€æœ‰neighborhoodidçš„è¡¨æ ¼é‡Œæå–å‡ºæ¥ï¼Œç„¶åç©ºç™½æ—¥æœŸå¡«0ï¼‰ï¼Œs_s_countï¼Œasb_priority
ç°æœ‰è¡¨æ ¼ï¼šâ‘ ï¼šLondon_SS_ASB neighborhoodidï¼Œæœ‰s_sçš„æ—¥æœŸ
â‘¡  neigh_priority_key_202311ï¼šneigh_idï¼Œ ASB_keywordsï¼Œpriority_date
æ–°å»ºä¸€ä¸ªè¡¨æ ¼ï¼šæ ¹æ®London_SS_ASBçš„neighborhoodidæ‰©å±•ï¼Œæ–°å»ºæ—¥æœŸåˆ—30*idï¼Œfor loop å¦‚æœè¡¨â‘ çš„æ—¥æœŸå­˜åœ¨=1ï¼Œå¦åˆ™=0ï¼›åŒç†neigh_priority_key_202311

- This function is to add a column of corresponding neighborhood id for each S&S point.
```{r eval=FALSE}
Get_SS_neigh_id <- function(points_sf, polygons_sf){
  # use st_within() to find which neighborhood boundary each s&s point is located in
  matched <- st_within(points_sf, polygons_sf, sparse = FALSE)

  # create a new column to store polygon ID, apply a function that to each row of matched(1 means rows of a matrix)
  points_sf$neigh_id <- apply(matched, 1, function(x) {
    # Check if the current row (corresponding to one point) is inside any polygon
    if (any(x)) {
      # if yes, assign the current row value of polygons_sf$neigh_id to the corresponding value of points_sf$neigh_id
        # which(x) return the position indices of all TRUE values of bool vector x 
      return(polygons_sf$neigh_id[which(x)])
      } 
    else {return(NA)}
    }
  )
  return(points_sf)
}
```

```{r eval=FALSE}
London_SS_ASB <- Get_SS_neigh_id(London_SS_ASB, London_neighborhoods_sf)
London_SS_Drug <- Get_SS_neigh_id(London_SS_Drug, London_neighborhoods_sf)
London_SS_Theft <- Get_SS_neigh_id(London_SS_Theft, London_neighborhoods_sf)

# convert the datetime format into Y%-M%-D% format
London_SS_ASB$date <- as.Date(unlist(lapply(London_SS_ASB$datetime , function(x) {
  return(as.Date(paste0(year(x), "-", month(x), "-", day(x))))
})))

London_SS_Drug$date <- as.Date(unlist(lapply(London_SS_Drug$datetime , function(x) {
  return(as.Date(paste0(year(x), "-", month(x), "-", day(x))))
})))

London_SS_Theft$date <- as.Date(unlist(lapply(London_SS_Theft$datetime , function(x) {
  return(as.Date(paste0(year(x), "-", month(x), "-", day(x))))
})))
```

```{r echo=FALSE}
# saveRDS(London_SS_ASB, "RDS_data/London_SS_ASB.rds")
London_SS_ASB<- readRDS("RDS_data/London_SS_ASB.rds")
# London_SS_ASB

# saveRDS(London_SS_ASB, "RDS_data/London_SS_Drug.rds")
London_SS_Drug<- readRDS("RDS_data/London_SS_Drug.rds")
# London_SS_Drug

# saveRDS(London_SS_ASB, "RDS_data/London_SS_Theft.rds")
London_SS_Theft<- readRDS("RDS_data/London_SS_Theft.rds")
# London_SS_Theft

```

- count the specific S&S type and Priority grouped by neigh_id
```{r paged.print=TRUE}
# Keep the neighborhood IDs with non-zero occurrences of each theme word during the research period
neigh_priority_ASB <- neigh_priority_key_202311 %>% select(neigh_id, ASB_keywords) %>%
                      filter(!(ASB_keywords == 0)) %>% arrange(desc(ASB_keywords))
neigh_priority_ASB                         

neigh_priority_Drug <- neigh_priority_key_202311 %>% select(neigh_id, Drug_keywords) %>%
                       filter(!(Drug_keywords == 0)) %>% arrange(desc(Drug_keywords))
neigh_priority_Drug

neigh_priority_Theft <- neigh_priority_key_202311 %>% select(neigh_id, Theft_keywords) %>%
                        filter(!(Theft_keywords == 0)) %>% arrange(desc(Theft_keywords))
neigh_priority_Theft

# Count the different types of S&S for each neighborhood, remove neighborhood with NA values, and sort them in descending order

neigh_SS_ASB <- as_tibble(London_SS_ASB) %>% 
                    group_by(neigh_id) %>% 
                    summarise(ss_ASB_count = n()) %>% 
                    filter(!(is.na(neigh_id))) %>% 
                    arrange(desc(ss_ASB_count))
neigh_SS_ASB

neigh_SS_Drug <- as_tibble(London_SS_Drug) %>% 
                    group_by(neigh_id) %>% 
                    summarise(ss_Drug_count = n()) %>% 
                    filter(!(is.na(neigh_id))) %>% 
                    arrange(desc(ss_Drug_count))
neigh_SS_Drug

neigh_SS_Theft <- as_tibble(London_SS_Theft) %>% 
                    group_by(neigh_id) %>% 
                    summarise(ss_Theft_count = n()) %>% 
                    filter(!(is.na(neigh_id))) %>% 
                    arrange(desc(ss_Theft_count))
neigh_SS_Theft
```

- count the specific S&S type and Priority grouped by both neigh_id and date
```{r}
 # S&S
neigh_date_SS_ASB <- as_tibble(London_SS_ASB) %>% group_by(neigh_id, date) %>% summarise(ss_ASB_count = n())
neigh_date_SS_ASB

neigh_date_SS_Drug <- as_tibble(London_SS_Drug) %>% group_by(neigh_id, date) %>% summarise(ss_Drug_count = n())
neigh_date_SS_Drug

neigh_date_SS_Theft <- as_tibble(London_SS_Theft) %>% group_by(neigh_id, date) %>% summarise(ss_Theft_count = n())
neigh_date_SS_Theft

 # Priority
neigh_date_priority_ASB <- neigh_priority_key_202311 %>% group_by(neigh_id, priority_date) %>% summarise(keyword_ASB_count = sum(ASB_keywords))
neigh_date_priority_ASB

neigh_date_priority_Drug <- neigh_priority_key_202311 %>% group_by(neigh_id, priority_date) %>% summarise(keyword_Drug_count = sum(Drug_keywords))
neigh_date_priority_Drug

neigh_date_priority_Theft <- neigh_priority_key_202311 %>% group_by(neigh_id, priority_date) %>% summarise(keyword_Theft_count = sum(Theft_keywords))
neigh_date_priority_Theft
```

è¿™ä¹ˆå¤šä¸ªidå¤ªå¤¸å¼ äº†ï¼Œç”¨keywordçš„idï¼ˆæ’åå‰å‡ ï¼‰æ¥ç¼©å‡ï¼
â‘  ç­›é€‰å‡ºLondon_SS_ASBå’Œneigh_priority_ASBä¸­åŒæ—¶å­˜åœ¨çš„é‚»é‡Œid
â‘¡ å°†æŒ‰neighbor_id å’Œ dateè®¡æ•°çš„ss å’Œ priorityå·¦å…³è”åˆ°ä¸€ä¸ªexpanded tibbleä¸Šï¼ŒæœªåŒ¹é…çš„è¡Œèµ‹å€¼ä¸º0
- This function is to 
```{r}
Get_SS_time_series <- function(neigh_date_SS_type, neigh_date_priority_type){
  # â‘  find those neighborhoods which has specific type of S&S and priority at the same time
  neigh_id_ss_priority <- intersect(unique(neigh_date_SS_type$neigh_id), unique(neigh_date_priority_type$neigh_id))
  
  # â‘¡ create a date data sequence from 2023-11-01 to 2023-11-30
  dates_nov_2023 <- unlist(seq(from = as.Date("2023-11-01"), to = as.Date("2023-11-30"), by = "day"))
  
  # â‘¢ create a tibble with each date in Dec as a row for each neighborhood 
  ss_priority_type <- as_tibble_col(neigh_id_ss_priority, column_name = "neigh_id") %>% crossing(date = dates_nov_2023)
  
  # â‘£ left_join() keeps all observations in ss_priority_type, if matched, get the S&S data, else remain NA
  ss_priority_type <- left_join(ss_priority_type, neigh_date_SS_type, by = c("neigh_id" = "neigh_id", "date" = "date")) 
  ss_priority_type <- left_join(ss_priority_type, neigh_date_priority_type, by = c("neigh_id" = "neigh_id", "date" = "priority_date"))
  
  # â‘¤ convert all NA to 0
  ss_priority_type <- ss_priority_type %>%
                      mutate(across(everything(), ~ replace_na(., 0)))
  
  # â‘¥ add neighborhood names to the tibble
  neigh_id_name <- London_neighborhoods_tibble %>% select(neigh_id, neigh_name)
  ss_priority_type <- left_join(ss_priority_type, neigh_id_name, by = c("neigh_id" = "neigh_id")) 
  
  return(ss_priority_type)
}
```

```{r}
ss_priority_ASB <- Get_SS_time_series(neigh_date_SS_ASB, neigh_date_priority_ASB)
ss_priority_ASB

ss_priority_Drug <- Get_SS_time_series(neigh_date_SS_Drug, neigh_date_priority_Drug)
ss_priority_Drug

ss_priority_Theft <- Get_SS_time_series(neigh_date_SS_Theft, neigh_date_priority_Theft)
ss_priority_Theft
```

```{r}
# saveRDS(ss_priority_ASB, "RDS_data/ss_priority_ASB.rds")
ss_priority_ASB<- readRDS("RDS_data/ss_priority_ASB.rds")
# ss_priority_ASB

# saveRDS(ss_priority_Drug, "RDS_data/ss_priority_Drug.rds")
ss_priority_Drug<- readRDS("RDS_data/ss_priority_Drug.rds")
# ss_priority_Drug

# saveRDS(ss_priority_Theft, "RDS_data/ss_priority_Theft.rds")
ss_priority_Theft<- readRDS("RDS_data/ss_priority_Theft.rds")
# ss_priority_Theft
```

```{r}
outlier <- ss_priority_ASB %>% filter(neigh_id == "E05013806N")

# å»æ‰å¼‚å¸¸å€¼
ss_priority_ASB <- ss_priority_ASB %>% filter(!(neigh_id == "E05013806N"))
```

é‚£å¾—ä¸‰ä¸ªæœˆçš„æ•°æ®æ‰èƒ½çœ‹å‡ºæ¥å§ï¼Ÿå‰åä¸¤ä¸ªæœˆ
```{r}
# å‡è®¾dfæ˜¯ä½ çš„æ•°æ®æ¡†

# æ·»åŠ åˆ†ç»„å˜é‡
ss_priority_ASB$group <- cut(ss_priority_ASB$neigh_id, breaks = 3, labels = c("Group1", "Group2", "Group3"))

# æ ¹æ®åˆ†ç»„å˜é‡ç»˜å›¾
p <- ggplot(df, aes(x = x, y = y, group = sample_id)) + 
     geom_line() +
     facet_wrap(~ group)

# æ‰“å°æˆ–ä¿å­˜ç»˜å›¾
print(p)

```

```{r}
ss_priority_ASB_1 <- slice(ss_priority_ASB, 1:(20*30))
ss_priority_ASB_1$sample_id <- 1
ss_priority_ASB_2 <- slice(ss_priority_ASB, (21*30):(40*30))
ss_priority_ASB_2$sample_id <- 2
ss_priority_ASB_3 <- slice(ss_priority_ASB, (41*30):(60*30))
ss_priority_ASB_3$sample_id <- 3
ss_priority_ASB_4 <- slice(ss_priority_ASB, (61*30):(40*77))
ss_priority_ASB_4$sample_id <- 1

ss_priority_ASB <- rbind(ss_priority_ASB_1, ss_priority_ASB_2, ss_priority_ASB_3, ss_priority_ASB_4)
```
ä¸‰ä¸ªç±»å‹é€‰å‡ ä¸ªå¾—äº†ï¼ˆå…ˆåˆ†æ‰¹ï¼Œå†é€‰ä¸€ä¸ªæ”¾å‡ºæ¥çœ‹çœ‹ï¼‰
```{r eval=FALSE, fig.height=5, fig.width=10}

Time_series_plot <- function(){
  SS_linechart_type <-  
  ggplot() +  
  geom_line(data = ss_priority_ASB_2, 
            aes(x = date,
                y = ss_ASB_count,
                color = neigh_name),
            linewidth = 0.8) +
  geom_point(data = ss_priority_ASB_2,
             aes(x = date,
                 y = ss_ASB_count,
                 color = neigh_name,
                 size = keyword_ASB_count)) +
  scale_color_viridis(option = "turbo", direction = -1, discrete = TRUE) +
  labs(title = "Relationship between S&S and Priority for %s in time series", 
       x = "Date", 
       y = "The number of S&S") + 
  # scale_color_manual(values = c('C6M_mean' = 'blue4', 'E1_mean' = 'pink3'),
  #                    labels = c('C6M_mean' = 'Stay-at-home Restrictions', 'E1_mean' = 'Income Support')) +
  theme(
      rect = element_blank(), # remove background
      plot.title = element_text(size =12, hjust =0.5, vjust = 0.5),
      legend.position = "right",
      strip.text = element_text(size = 10), 
      panel.spacing = unit(1, "lines"),
      panel.border = element_rect(colour = "black", fill=NA, linewidth=0.5),
      # legend.position = "",
      legend.background = element_blank(),
      legend.key = element_rect(fill = "transparent"),
      legend.key.size = unit(0.5, "cm"),
      legend.text = element_text(size = 10)
      ) 
  SS_linechart_type
return(SS_linechart_type)
}

```
# 4 Conclusion
æ€»ç»“åˆ°åº•æ˜¯å› ä¸ºä»€ä¹ˆåè§
# 5 Reference

# 6 Code Appendix
```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE} 
# this chunk generates the complete code appendix. 
```
